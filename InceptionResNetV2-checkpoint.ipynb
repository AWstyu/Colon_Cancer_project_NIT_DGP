{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c5f00-b5c0-4649-9eb1-bae742483576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\COLON_CANCER DATASET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372264f0-d3f4-46e5-b8eb-6771e4d0940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_train = np.load(\"CONCATENATED_FEATURES_TRAIN_InceptionResNetV2.npy\")  \n",
    "y_train = np.load(\"Training_labels.npy\")    \n",
    "X_val = np.load(\"CONCATENATED_FEATURES_VALIDATE_InceptionResNetV2.npy\")\n",
    "y_val = np.load(\"Validation_labels.npy\")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "\n",
    "\n",
    "num_classes = 5  \n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def build_mlp(input_shape=(1536,), num_classes=5):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Dense(1024, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-4))(inputs)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.6)(x)\n",
    "    \n",
    "    x = layers.Dense(512, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.6)(x)\n",
    "    \n",
    "    x = layers.Dense(256, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.55)(x)\n",
    "    \n",
    "    x = layers.Dense(128, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(64, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(32, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.45)(x)\n",
    "\n",
    "    x = layers.Dense(16, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)  \n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    optimizer = optimizers.AdamW(learning_rate=0.01, weight_decay=1e-4, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_mlp()\n",
    "    model.summary()\n",
    "    \n",
    "    lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[lr_scheduler])\n",
    "    \n",
    "    \n",
    "    log_data = []\n",
    "    for epoch in range(0, len(history.history['accuracy']), 10):\n",
    "        log_data.append([\n",
    "            epoch,\n",
    "            history.history['accuracy'][epoch],\n",
    "            history.history['loss'][epoch],\n",
    "            history.history['val_accuracy'][epoch],\n",
    "            history.history['val_loss'][epoch]\n",
    "        ])\n",
    "\n",
    "    if (len(history.history['accuracy']) - 1) % 10 != 0:\n",
    "        last_epoch = len(history.history['accuracy']) - 1\n",
    "        log_data.append([\n",
    "            last_epoch,\n",
    "            history.history['accuracy'][last_epoch],\n",
    "            history.history['loss'][last_epoch],\n",
    "            history.history['val_accuracy'][last_epoch],\n",
    "            history.history['val_loss'][last_epoch]\n",
    "        ])\n",
    "    \n",
    "   \n",
    "    log_df = pd.DataFrame(log_data, columns=['Epoch', 'Training Accuracy', 'Training Loss', 'Validation Accuracy', 'Validation Loss'])\n",
    "    print(log_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2fb27-230b-49d7-8954-9ff720f226d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.save(\"mlp_model_InceptionResNetV2.h5\")\n",
    "\n",
    "print(\"Model saved successfully!!\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy for InceptionResNetV2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee312d-d814-4cf8-87a6-55276b8110a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "directory = \"C:\\\\COLON_CANCER DATASET\\\\PolypDB\\\\PolypDB_modality_wise\\\\AUG_PICS\\\\Model_Test_Feature_PKLs\\\\InceptionResNetV2\"\n",
    "\n",
    "\n",
    "modalities = [\"bli\", \"wli\", \"nbi\", \"fice\", \"lci\"]\n",
    "\n",
    "\n",
    "for modality in modalities:\n",
    "    con_features = []\n",
    "    count = 0\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if modality in file.lower():  \n",
    "            filename = os.path.join(directory, file)\n",
    "            count += 1\n",
    "            with open(filename, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                l = len(data)\n",
    "                con_features.append(data)\n",
    "\n",
    "    if count > 0:\n",
    "       \n",
    "        con_features_arr = np.concatenate(con_features, axis=0)\n",
    "        con_features_mod = con_features_arr.reshape(count, l)\n",
    "\n",
    "        \n",
    "        np.save(f\"CONCATENATED_FEATURES_TEST_{modality.upper()}_InceptionResNetV2.npy\", con_features_mod)\n",
    "\n",
    "        print(f\"Saved {modality.upper()} test features successfully! Shape: {con_features_mod.shape}\")\n",
    "    else:\n",
    "        print(f\"No files found for {modality.upper()}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4186d3f-9d2c-43bc-b69b-1dcc8e489ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, log_loss\n",
    "\n",
    "\n",
    "model = load_model(\"mlp_model_InceptionV3.h5\")\n",
    "\n",
    "\n",
    "modalities = [\"BLI\", \"WLI\", \"FICE\", \"LCI\", \"NBI\"]\n",
    "label_order = [\"BLI\", \"FICE\", \"LCI\", \"NBI\", \"WLI\"]\n",
    "label_map = {modality: idx for idx, modality in enumerate(label_order)}\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, modality):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(5))\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=label_order, yticklabels=label_order)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix - {modality}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "l_dense = []\n",
    "\n",
    "\n",
    "for modality in modalities:\n",
    "    X_test = np.load(f\"CONCATENATED_FEATURES_TEST_{modality}_InceptionV3.npy\")\n",
    "    \n",
    "   \n",
    "    modality_label = label_map[modality]\n",
    "    y_test = np.full(shape=(len(X_test),), fill_value=modality_label)\n",
    "\n",
    "    num_classes = 5  \n",
    "    y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "   \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    logloss = log_loss(y_test_one_hot, y_pred_probs)\n",
    "    l_dense.append(logloss)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "   \n",
    "    print(f\"Results for {modality}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Log Loss: {logloss:.4f}\")\n",
    "    print(f\"Unique labels in y_test: {np.unique(y_test)}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    \n",
    "    plot_confusion_matrix(y_true, y_pred, modality)\n",
    "\n",
    "\n",
    "print(f\"Average Log_loss for the InceptionV3: {sum(l_dense)/5:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
